\newpage
\setcounter{page}{1}
\renewcommand{\thesection}{\S \arabic{section}}
\renewcommand{\theHsection}{sisection. \arabic{section}}

# Supplementary information {-}

\setcounter{section}{0}

# Additional information about the SwehVd databasee

## Participant recruitment {#sec:recruitment -}
Participants were recruited through word-of-mouth, flyers at Stockholm University Campus, and online channels (accindi.se). Figure \@ref(fig:flyer) is an example of flyers distributed at Stockholm University Campus. The flyer gives information on criteria for participation, recording procedure, reimbursement and contact information to experimenter (first author).

(ref:flyer) Example flyer for recruiting Stockholm Swedish talkers for recording of the SwehVd database.

```{r flyer, out.width='65%', fig.cap="(ref:flyer)"}
include_graphics("ad_recruitment.png")
```

## Word list
Word list with all target and filler words, recorded by all talkers in the SwehVd database.

\begin{table}
\caption{\label{tab:word-list}Words recorded by the female talkers of Stockholm Swedish for the SwehVd database}
\centering
\begin{tabular}[t]{c|c}
\hline
Target words&Vowel IPA\\
\hline
hid&`r linguisticsdown::cond_cmpl("[iː]")`\\
\hline
hidd&`r linguisticsdown::cond_cmpl("[ɪ]")`\\
\hline
hyd&`r linguisticsdown::cond_cmpl("[yː]")`\\
\hline
hydd&`r linguisticsdown::cond_cmpl("[ʏ]")`\\
\hline
hed&`r linguisticsdown::cond_cmpl("[eː]")`\\
\hline
hedd&`r linguisticsdown::cond_cmpl("[ɛ]")`\\
\hline
häd&`r linguisticsdown::cond_cmpl("[ɛː]")`\\
\hline
hädd&`r linguisticsdown::cond_cmpl("[ɛ]")`\\
\hline
härd&`r linguisticsdown::cond_cmpl("[æː]")`\\
\hline
härr&`r linguisticsdown::cond_cmpl("[æ]")`\\
\hline
höd&`r linguisticsdown::cond_cmpl("[øː]")`\\
\hline
hödd&`r linguisticsdown::cond_cmpl("[ø]")`\\
\hline
hörd&`r linguisticsdown::cond_cmpl("[œː]")`\\
\hline
hörr&`r linguisticsdown::cond_cmpl("[œ]")`\\
\hline
hud&`r linguisticsdown::cond_cmpl("[ʉː]")`\\
\hline
hudd&`r linguisticsdown::cond_cmpl("[ɵ]")`\\
\hline
hod&`r linguisticsdown::cond_cmpl("[uː]")`\\
\hline
hodd&`r linguisticsdown::cond_cmpl("[ʊ]")`\\
\hline
håd&`r linguisticsdown::cond_cmpl("[oː]")`\\
\hline
hådd&`r linguisticsdown::cond_cmpl("[ɔ]")`\\
\hline
had&`r linguisticsdown::cond_cmpl("[ɑː]")`\\
\hline
hadd&`r linguisticsdown::cond_cmpl("[a]")`\\
\hline
\end{tabular}
\hspace{2em}
\begin{tabular}[t]{c|c}
\hline
\multicolumn{2}{c}{Filler words}\\
\hline
titt&tand\\
\hline
damm&dipp\\
\hline
tå&buss\\
\hline
bål&ding\\
\hline
dill&porr\\
\hline
tugga&mitt\\
\hline
mat&dopp\\
\hline
norr&tal\\
\hline
must&namn\\
\hline
pil&pall\\
\hline
dina&bar\\
\hline
biff&till\\
\hline
Tina&mål\\
\hline
borr&Nina\\
\hline
dal&då\\
\hline
Pål&nick\\
\hline
nunna&ditt\\
\hline
mil&dugga\\
\hline
ting&mall\\
\hline
ball&bil\\
\hline
piff&par\\
\hline
tipp&morr\\
\hline
puss&nav\\
\hline
topp&nå\\
\end{tabular}
\end{table}


# Per-vowel categorization accuracy of models trained on long and short vowels separately {#sec:accuracy-per-vowel -}

```{r cache.lazy=FALSE}
#Plot the overall accuracy of the different normalization accounts
plot_io_results_per_vowel <- function(data) {
  data %>%
  # Rename IO.Normalization.Type for plotting
  mutate(
    IO.Normalization.Type =
      factor(
        plyr::mapvalues(IO.Normalization.Type, levels.normalization.plots, labels.normalization),
        levels = labels.normalization)) %>%
    unnest(posterior_of_intended_vowel) %>%
    # Get the CI over the five folds
    { if ("IO.Quantity" %in% names(data)) group_by(., IO.Normalization.Type, IO.Quantity, IO.crossvalidation_group, Intended.Vowel, Cue_space) else group_by(., IO.Normalization.Type, IO.crossvalidation_group, Intended.Vowel, Cue_space) } %>%
    summarise(
      chance = 1 / n_distinct(Intended.Vowel),
      ci = list(enframe(Hmisc::smean.cl.boot(Posterior)))) %>%
    unnest(ci) %>%
    spread(name, value) %>%
    { if ("IO.Quantity" %in% names(data)) group_by(., IO.Normalization.Type, IO.Quantity, Intended.Vowel, Cue_space) else  group_by(., IO.Normalization.Type, Intended.Vowel, Cue_space) } %>%
    summarise(
      chance = first(chance),
      mean_CI_lower = mean(Lower),
      mean_CI_upper = mean(Upper),
      mean = mean(Mean)) %>%
    ggplot() +
    geom_pointrange(
      aes(x = IO.Normalization.Type,
          y = mean,
          ymin = mean_CI_lower,
          ymax = mean_CI_upper,
          color = IO.Normalization.Type),
      position = position_dodge2(width = 0.3),
      fatten = 2.5) +
    geom_text(mapping = 
                 aes(x = IO.Normalization.Type,
                     y = mean_CI_upper + .01,
                     colour = IO.Normalization.Type,
                     label = sprintf("%0.1f", mean)),
               alpha = .85,
               size = 2.5,
               angle = 90,
               hjust = 0) +
    geom_hline(aes(yintercept = case_when(IO.Quantity == "long" ~ 1/11,
                                          IO.Quantity == "short" ~ 1/10,
                                          IO.Quantity == "all" ~ 1/21)), color = "gray", linetype = 2) +
    scale_y_continuous("Accuracy (of predicting *intended* vowel)", limits = c(0,1))+
    scale_colour_manual(
      "Normalization \nprocedure of IO",
      labels = labels.normalization.1SG,
      values = colors.all.procedures.1SG) +
    guides(color = "none") +
    theme(axis.text.x = ggtext::element_markdown(angle = 60, vjust = 1, hjust = 1, colour = colors.all.procedures.1SG, size = 7),
        axis.title.x = element_blank())
}
```

```{r}
#Do multiple plots because of plot size
p.accuracy.io.per.vowel.long.1 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "long") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[iː]", "[yː]", "[ʉː]", "[eː]", "[ɛː]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe))
p.accuracy.io.per.vowel.long.2 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "long") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[æː]", "[øː]", "[œː]", "[ɑː]", "[oː]", "[uː]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe))

axis.title.accuracy <- grid::textGrob("Accuracy (of predicting *intended* vowel)", gp=grid::gpar(fontface="bold", fontsize=8), rot=90)

p.accuracy.io.per.vowel.short.1 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "short") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[ɪ]", "[ʏ]", "[ɵ]", "[ɛ]", "[æ]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe)) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank())
p.accuracy.io.per.vowel.short.2 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "short") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[ø]", "[œ]", "[a]", "[ɔ]", "[ʊ]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe))

p.accuracy.io.per.vowel.all.1 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "all") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[iː]", "[ɪ]", "[yː]", "[ʏ]", "[ʉː]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe)) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank())
p.accuracy.io.per.vowel.all.2 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "all") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[ɵ]", "[eː]", "[ɛ]", "[ɛː]", "[æː]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe))
p.accuracy.io.per.vowel.all.3 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "all") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[æ]", "[øː]", "[ø]", "[œː]", "[œ]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe)) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank())
p.accuracy.io.per.vowel.all.4 <- plot_io_results_per_vowel(
  m.io.SwehVd %>%
    filter(IO.Quantity == "all") %>%
    nplyr::nest_filter(posterior_of_intended_vowel, Intended.Vowel %in% c("[ɑː]", "[a]", "[oː]", "[ɔ]", "[uː]", "[ʊ]"))) +
  facet_grid(Cue_space ~  factor(Intended.Vowel, levels = levels.vowel.IPA.swe))
```
(ref:predictions-per-vowel-long) Per-vowel predicted categorization accuracy of the ideal observers trained on the **long** vowels, under different assumptions about the relevant cues. Point ranges indicate the average mean accuracy and average 95% bootstrapped CI across the five folds. Chance level is indicated by grey line.

\begin{landscape}

```{r predictions-per-vowel-long, fig.width=base.width * 5, fig.height=base.height * 3, fig.align='center', out.width='90%', fig.cap="(ref:predictions-per-vowel-long)"}
p.accuracy.io.per.vowel.long.1
```
\end{landscape}

(ref:predictions-per-vowel-long-2) (*Continued from last page*)Per-vowel predicted categorization accuracy of the ideal observers trained on the **long** vowels, under different assumptions about the relevant cues. Point ranges indicate the average mean accuracy and average 95% bootstrapped CI across the five folds. Chance level is indicated by grey line.

\begin{landscape}

```{r predictions-per-vowel-long-2, fig.width=base.width * 5, fig.height=base.height * 3, fig.align='center', out.width='90%', fig.cap="(ref:predictions-per-vowel-long-2)"}
p.accuracy.io.per.vowel.long.2
```
\end{landscape}

(ref:predictions-per-vowel-short) Per-vowel predicted categorization accuracy of the ideal observers trained on the **short** vowels, under different assumptions about the relevant cues. Point ranges indicate the average mean accuracy and average 95% bootstrapped CI across the five folds. Chance level is indicated by grey line.

```{r predictions-per-vowel-short, fig.width=base.width * 4, fig.height=base.height * 5, fig.align='center', out.width='90%', fig.cap="(ref:predictions-per-vowel-short)"}
p.accuracy.io.per.vowel.short <- cowplot::plot_grid(p.accuracy.io.per.vowel.short.1, NULL, p.accuracy.io.per.vowel.short.2 + theme(axis.title.y = element_blank()), ncol = 1, align = "hv", axis = "l", rel_heights = c(1,-.15,1))
gridExtra::grid.arrange(gridExtra::arrangeGrob(p.accuracy.io.per.vowel.short, left = axis.title.accuracy))
```

(ref:predictions-per-vowel-all-1) Per-vowel predicted categorization accuracy of the ideal observers trained on **all** vowels, under different assumptions about the relevant cues. Point ranges indicate the average mean accuracy and average 95% bootstrapped CI across the five folds. Chance level is indicated by grey line.

```{r predictions-per-vowel-all-1, fig.width=base.width * 4, fig.height=base.height * 5, fig.align='center', out.width='90%', fig.cap="(ref:predictions-per-vowel-all-1)"}
p.accuracy.io.per.vowel.all.first <- cowplot::plot_grid(p.accuracy.io.per.vowel.all.1, NULL, p.accuracy.io.per.vowel.all.2 + theme(axis.title.y = element_blank()), ncol = 1, align = "hv", axis = "l", rel_heights = c(1,-.15,1))
gridExtra::grid.arrange(gridExtra::arrangeGrob(p.accuracy.io.per.vowel.all.first, left = axis.title.accuracy))
```

(ref:predictions-per-vowel-all-2) (*Continued from last page*)Per-vowel predicted categorization accuracy of the ideal observers trained on **all** vowels, under different assumptions about the relevant cues. Point ranges indicate the average mean accuracy and average 95% bootstrapped CI across the five folds. Chance level is indicated by grey line.

```{r predictions-per-vowel-all-2, fig.width=base.width * 4.5, fig.height=base.height * 5, fig.align='center', out.width='90%', fig.cap="(ref:predictions-per-vowel-all-2)"}
p.accuracy.io.per.vowel.all.second <- cowplot::plot_grid(
  cowplot::plot_grid(p.accuracy.io.per.vowel.all.3, NULL, rel_widths = c(5/6, 1/6), align = "hv", axis = "l"),
                     p.accuracy.io.per.vowel.all.4 + theme(axis.title.y = element_blank()), ncol = 1, align = "hv", axis = "l", rel_heights = c(3/7, 3.5/7))
gridExtra::grid.arrange(gridExtra::arrangeGrob(p.accuracy.io.per.vowel.all.second, left = axis.title.accuracy))
```

\newpage

# Confusion and difference matrices of ideal observers {#sec:confusion -}
To further explore effects of neighbouring categories, and which categories are more easily confused by the models and with what, we plot confusion matrices of the worst and best performing models trained on the long, short or all Central Swedish vowels, under the different assumptions about the relevant cues. Next to the confusion matrices, we plot difference matrices to facilitate comparison.

```{r, echo=FALSE}
# Keep code for reproducibility
# run a model assessing the difference in performance between models as a function of the normalization scheme.
# data.io <- m.io.SwehVd.F1F2 %>%
#   unnest(posterior_of_intended_vowel) %>%
#   mutate(IO.Normalization.Type = factor(IO.Normalization.Type, levels = levels.normalization.plots, labels = labels.normalization))

#Add treatment coding for IO.Normalization.Type
#contrasts(data.io$IO.Normalization.Type) = contr.treatment(16)
# # contrasts(data.io$IO.cue_normalization) = cbind(
# #   "C-CuRE Hz" = c(0, 1, 0, 0, 0, 0, 0),
# #   "Lobanov Hz" = c(0, 0, 1, 0, 0, 0, 0),
# #   "Gerstman Hz" = c(0, 0, 0, 1, 0, 0, 0),
# #   "Nearey1 log" = c(0, 0, 0, 0, 1, 0, 0),
# #   "Nearey2 log" = c(0, 0, 0, 0, 0, 1, 0),
# #   "Miller log" = c(0, 0, 0, 0, 0, 0, 1))
# 
# model <- glm(Posterior ~ IO.Normalization.Type, family=gaussian, data = data.io)
# summary(model)
```
```{r}
plot_io_confusion <- function(
  data,
  cols = cols) {
  data %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = cols,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    { if ("IO.Quantity" %in% names(data)) group_by(., IO.Vowel, Intended.Vowel, IO.Normalization.Type, IO.Quantity, Cue_space) else group_by(., IO.Vowel, Intended.Vowel, IO.Normalization.Type, Cue_space) } %>%
    summarise(across(.cols = Posterior, mean, na.rm = T)) %>%
    ggplot(
      aes(
        x = factor(Intended.Vowel, levels = levels.vowel.IPA.swe),
        y = factor(IO.Vowel, levels = levels.vowel.IPA.swe),
        fill = Posterior)) +
    geom_raster() +
    scale_x_discrete("Intended vowel", expand = c(0,0)) +
    scale_y_discrete("IO response vowel", expand = c(0,0)) +
    scale_fill_viridis_b("Posterior \nprobability \nunder \nideal observer", limits = c(0,1), breaks = seq(0, 1, .1)) +
    facet_grid(Cue_space ~ IO.Normalization.Type) +
    theme(axis.title.x = element_blank(), 
          axis.title.y = element_blank())
}
```

```{r }
# Make confusion matrices of best and worst for all cue evaluations under the assumption of long, short or all vowels
p.confusion.long.F1F2 <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Miller_log", "Lobanov_Hz"), Cue_space == "F1-F2", IO.Quantity == "long"),
                         cols = levels.vowel.IPA.swe.long) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Miller_log", "Lobanov_Hz"), labels = c("Miller (log)", "Lobanov (Hz)"))) + theme(legend.position="none")
p.confusion.long.F1F3 <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Miller_log", "Lobanov_Hz"), Cue_space == "F1-F3", IO.Quantity == "long"),
                         cols = levels.vowel.IPA.swe.long) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Miller_log", "Lobanov_Hz"), labels = c("Miller (log)", "Lobanov (Hz)"))) + theme(legend.position="none")
p.confusion.long.all <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Gerstman_Hz", "Lobanov_Hz"), Cue_space == "F0-F3, duration", IO.Quantity == "long"),
                         cols = levels.vowel.IPA.swe.long) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Gerstman_Hz", "Lobanov_Hz"), labels = c("Gerstman (Hz)", "Lobanov (Hz)"))) + theme(legend.position="none")

p.confusion.short.F1F2 <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Miller_log", "CCuRE_Mel"), Cue_space == "F1-F2", IO.Quantity == "short"),
                         cols = levels.vowel.IPA.swe.short) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Miller_log", "CCuRE_Mel"), labels = c("Miller (log)", "C-CuRE (Mel)"))) + theme(legend.position="none")
p.confusion.short.F1F3 <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Miller_log", "CCuRE_Mel"), Cue_space == "F1-F3", IO.Quantity == "short"),
                         cols = levels.vowel.IPA.swe.short) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Miller_log", "CCuRE_Mel"), labels = c("Miller (log)", "C-CuRE (Mel)"))) + theme(legend.position="none")
p.confusion.short.all <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Gerstman_Hz", "Lobanov_Hz"), Cue_space == "F0-F3, duration", IO.Quantity == "short"),
                         cols = levels.vowel.IPA.swe.short) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type,  levels = c("Gerstman_Hz", "Lobanov_Hz"), labels = c("Gerstman (Hz)", "Lobanov (Hz)"))) + theme(legend.position="none")

p.confusion.all.F1F2 <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("SyrdalGopal_Bark", "Lobanov_Hz"), Cue_space == "F1-F2", IO.Quantity == "all"),
                         cols = levels.vowel.IPA.swe) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("SyrdalGopal_Bark", "Lobanov_Hz"), labels = c("SyrdalGopal (bark)", "Lobanov (Hz)"))) + theme(legend.position="none")
p.confusion.all.F1F3 <- plot_io_confusion(
    m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Miller_log", "Lobanov_Hz"), Cue_space == "F1-F3", IO.Quantity == "all"), 
    cols = levels.vowel.IPA.swe) + 
  facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Miller_log", "Lobanov_Hz"), labels = c("Miller (log)", "Lobanov (Hz)"))) + theme(legend.position="none")
p.confusion.all.all <- plot_io_confusion(
  m.io.SwehVd %>% filter(IO.Normalization.Type %in% c("Gerstman_Hz", "CCuRE_Hz"), Cue_space == "F0-F3, duration", IO.Quantity == "all"),
                         cols = levels.vowel.IPA.swe) +
    facet_grid(Cue_space ~ factor(IO.Normalization.Type, levels = c("Gerstman_Hz", "CCuRE_Hz"), labels = c("Gerstman (Hz)", "C-CuRE (Hz)")))

legend.confusion <- cowplot::get_legend(p.confusion.all.all +
  guides(fill = guide_legend(ncol = 1)))

# Plot a difference matrix, of differences in posteriors between worst and best performing models
# Diff matrices of the long vowels
p.diff.long.F1F2 <- p.confusion.long.F1F2 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.long,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F2", IO.Quantity == "long") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - Miller (log)" = Lobanov_Hz - Miller_log) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.long.F1F3 <- p.confusion.long.F1F3 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.long,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F3", IO.Quantity == "long") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - Miller (log)" = Lobanov_Hz - Miller_log) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.long.all <- p.confusion.long.all %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.long,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F0-F3, duration", IO.Quantity == "long") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - Gerstman (Hz)" = Lobanov_Hz - Gerstman_Hz) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
# Diff matrices of the short vowels
p.diff.short.F1F2 <- p.confusion.short.F1F2 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.short,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F2", IO.Quantity == "short") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference C-CuRE (Mel) - Miller (log)" = CCuRE_Mel - Miller_log) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.short.F1F3 <- p.confusion.short.F1F3 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.short,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F3", IO.Quantity == "short") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference C-CuRE (Mel) - Miller (log)" = CCuRE_Mel - Miller_log) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.short.all <- p.confusion.short.all %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe.short,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F0-F3, duration", IO.Quantity == "short") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - Gerstman (Hz)" = Lobanov_Hz - Gerstman_Hz) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
# Diff matrices of all vowels
p.diff.all.F1F2 <- p.confusion.all.F1F2 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F2", IO.Quantity == "all") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - SyrdalGopal (Bark)" = Lobanov_Hz - SyrdalGopal_Bark) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.all.F1F3 <- p.confusion.all.F1F3 %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F1-F3", IO.Quantity == "all") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference Lobanov (Hz) - Miller (log)" = Lobanov_Hz - Miller_log) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference in posterior probability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) + 
  theme(legend.position = "none")
p.diff.all.all <- p.confusion.all.all %+%
  (m.io.SwehVd %>%
    unnest(posterior_of_all_vowels) %>%
    pivot_longer(
    cols = levels.vowel.IPA.swe,
    values_to = "Posterior",
    names_to = "IO.Vowel") %>%
    filter(Cue_space == "F0-F3, duration", IO.Quantity == "all") %>%
    group_by(IO.Normalization.Type, IO.Vowel, Intended.Vowel) %>%
    summarise_at(vars(Posterior), mean) %>%
    pivot_wider(
      names_from = IO.Normalization.Type,
      values_from = Posterior) %>%
    mutate(
      "Difference C-CuRE (Hz) - Gerstman (Hz)" = CCuRE_Hz - Gerstman_Hz) %>%
    select(starts_with("Diff"), IO.Vowel, Intended.Vowel) %>%
    pivot_longer(
         cols = starts_with("Diff"),
         names_to = "Comparison",
         values_to = "Difference")) +
    aes(fill = Difference) +
    scale_fill_gradient2("Difference \nin posterior \nprobability", limits = c(-.25,.25), breaks = seq(-.25, .25, .05)) +
    facet_wrap(~ Comparison, ncol = 1) +
  theme(legend.position = "right")

legend.diff <- cowplot::get_legend(p.diff.all.all +
  guides(fill = guide_legend(ncol = 1)))
```

(ref:confusion-matrix-long) Illustration of the category-specific differences in predictions of the worst and best performing normalization models for each combination of cues (**rows**). The confusion matrices (**Panel A**) plot the predictions for the worst (**left**) and best (**right**) performing models in predicting the **long** vowels, under different assumptions about the relevant cues. Vowel intended by talker (x-axis) is plotted against vowel selected by ideal observer model (y-axis). Color fill indicates the posterior probability of the models predicting the intended vowel. The difference matrices (**Panel B**) illustrates the differences in predictions between the best and the worst performing models. Color fill indicates the difference in the posterior probability of the models predicting the intended vowel. More **purple** indicates an increase in posterior probability for the former over the latter model, more **red** indicates an advantage for the latter over the former.

\begin{landscape}

```{r confusion-matrix-long, fig.width=base.width*5, fig.height=base.height*4.5, fig.align='center', out.height='85%', fig.cap="(ref:confusion-matrix-long)"}
cowplot::plot_grid(
  cowplot::plot_grid(legend.confusion,
                     cowplot::plot_grid(p.confusion.long.F1F2, p.confusion.long.F1F3, p.confusion.long.all, align = "hv", axis = "btlr", ncol = 1),
                     ncol = 2, rel_widths = c(1/8,7/8)),
  cowplot::plot_grid(cowplot::plot_grid(p.diff.long.F1F2, p.diff.long.F1F3, p.diff.long.all, align = "hv", axis = "btlr", ncol = 1), legend.diff,
                     ncol = 2, rel_widths = c(4/5,1/5)),
  ncol = 2, rel_widths = c(.65,.35), labels = c("A", "B"))
```
\end{landscape}
(ref:confusion-matrix-short) Illustration of the category-specific differences in predictions of the worst and best performing normalization models for each combination of cues (**rows**). The confusion matrices (**Panel A**) plot the predictions for the worst (**left**) and best (**right**) performing models in predicting the **short** vowels, under different assumptions about the relevant cues. Vowel intended by talker (x-axis) is plotted against vowel selected by ideal observer model (y-axis). Color fill indicates the posterior probability of the models predicting the intended vowel. The difference matrices (**Panel B**) illustrates the differences in predictions between the best and the worst performing models. Color fill indicates the difference in the posterior probability of the models predicting the intended vowel. More **purple** indicates an increase in posterior probability for the former over the latter model, more **red** indicates an advantage for the latter over the former.

\begin{landscape}

```{r confusion-matrix-short, fig.width=base.width*5, fig.height=base.height*4.5, fig.align='center', out.height='85%', fig.cap="(ref:confusion-matrix-short)"}
cowplot::plot_grid(
  cowplot::plot_grid(legend.confusion,
                     cowplot::plot_grid(p.confusion.short.F1F2, p.confusion.short.F1F3, p.confusion.short.all, align = "hv", axis = "btlr", ncol = 1),
                     ncol = 2, rel_widths = c(1/8,7/8)),
  cowplot::plot_grid(cowplot::plot_grid(p.diff.short.F1F2, p.diff.short.F1F3, p.diff.short.all, align = "hv", axis = "btlr", ncol = 1), legend.diff,
                     ncol = 2, rel_widths = c(4/5,1/5)),
  ncol = 2, rel_widths = c(.65,.35), labels = c("A", "B"))
```

\end{landscape}

(ref:confusion-matrix-allVowels) Illustration of the category-specific differences in predictions of the worst and best performing normalization models for each combination of cues (**rows**). The confusion matrices (**Panel A**) plot the predictions for the worst (**left**) and best (**right**) performing models in predicting the **all** vowels, under different assumptions about the relevant cues. Vowel intended by talker (x-axis) is plotted against vowel selected by ideal observer model (y-axis). Color fill indicates the posterior probability of the models predicting the intended vowel. The difference matrices (**Panel B**) illustrates the differences in predictions between the best and the worst performing models. Color fill indicates the difference in the posterior probability of the models predicting the intended vowel. More **purple** indicates an increase in posterior probability for the former over the latter model, more **red** indicates an advantage for the latter over the former.

\begin{landscape}

```{r confusion-matrix-allVowels, fig.width=base.width*5, fig.height=base.height*4.5, fig.align='center', out.height='85%', fig.cap="(ref:confusion-matrix-allVowels)"}
cowplot::plot_grid(
  cowplot::plot_grid(legend.confusion,
                     cowplot::plot_grid(p.confusion.all.F1F2, p.confusion.all.F1F3, p.confusion.all.all + theme(legend.position = "none"), align = "hv", axis = "btlr", ncol = 1),
                     ncol = 2, rel_widths = c(1/8,7/8)),
  cowplot::plot_grid(cowplot::plot_grid(p.diff.all.F1F2, p.diff.all.F1F3, p.diff.all.all + theme(legend.position = "none"), align = "hv", axis = "btlr", ncol = 1), legend.diff,
                     ncol = 2, rel_widths = c(4/5,1/5)),
  ncol = 2, rel_widths = c(.65,.35), labels = c("A", "B"))
```

\end{landscape}

# Alternative approaches to evaluating normalization accounts: Comparing the effects of normalization accounts on between- vs. within-category variability {#sec:studyI -}
A large portion of previous studies evaluating normalization accounts against production data, has compared approaches in terms of how they affect category variability. In this additional study, we follow this traditional approach and evaluate how effectively different normalization accounts reduce the within-category variability of Central Swedish vowels. We visualize the vowel space under different normalization accounts, and assess the effects on vowel category variability by calculating a measure of category separability. To anticipate one take-home point, the results highlight important shortcomings of separability indices in evaluating normalization accounts and underlines the benefits of using a perceptual model to compare the effects of different normalization accounts.

```{r}
#Write table of previous studies
norm_accounts_eval <- tibble(
      "Language investigated" = c(
        "US English",
        "US English",
        "US English",
        "US English",
        "US English",
        "US English, Norwegian, Swedish, German, Danish, Dutch",
        "UK English",
        "UK English",
        "Russian"),

      "Article" = c(
               "Barreda & Nearey, 2018",
               "Clopper, 2009",
               "Hindle, 1978",
               "Kohn & Farrington, 2012",
               "Labov, 2010",
               "Disner, 1980",
               "Fabricius, Watt & Johnson, 2009",
               "Flynn & Foulkes, 2011",
               "Lobanov, 1971"),

  "Speech materials" = c(
                         "120,000 simulated languages (of 5 or 9 vowels) modeled on Hillenbrand et al.'s (1995) data (98 female/male child/adult talkers * 12 vowels)",
                         "2 female/male talkers from Ohio (1 token * 10 vowels)",
                         "Peterson & Barney's (1952) database; 19 female/male talkers from Philadelphia + 60 telephone informants (minimum 3 tokens per category; analysis focus on /ay/)",
                         "Longitudinal data from 10 female/male African American talkers from North Carolina (approx. 10 tokens * 10 vowels * 5 ages)",
                         "Peterson & Barney's (1952) database; Philadelphia/Linguistic Change and Variation project (120 female/male talkers, stratified for age, sociolinguistic factors)",  
                         "Differing number of tokens, vowels, and phonetic contexts across the six languages",
                         "20 old/young female/male talkers of Received pronunciation (11 vowels); 6 old/young female/male talkers of Aberdeen English (8 vowels in different phonetic contexts)",
                         "20 old/young female/male Nottingham talkers (mean 180 recordings per talker; categories not reported)",
                         "5 female/male talkers (9 vowels in different phonetic contexts)"),

  "Normalization accounts" = c(
    "Nearey2, Lobanov, log-mean in linear regression framework",                                     
    "Bladon et al.'s scale factor of 1 Bark (1994), Syrdal & Gopal, Nordström & Lindblom, Nearey1, Nearey2, Watt & Fabricius, Gerstman, Lobanov, Miller",
    "Nearey2, Nordström-Lindblom, Sankoff-Shorrock-McKay",
    "Lobanov, Gerstman, Nearey1, Nordström & Lindblom, Syrdal & Gopal/Thomas, Watt & Fabricius",
    "Nearey2, Nordström-Lindblom, Sankoff-Shorrock-McKay ",
    "Gerstman, Lobanov, Nearey2, Harshman's PARAFAC model",
    "Watt & Fabricius, Lobanov, Nearey1",
    "log-transformation (base 10), log-transformation (natural), Mel, ERB, Bark (*2 gender-specific versions), Syrdal & Gopal, Nordström (*2 gender-specific versions), LCE, Gerstman, Lobanov, Watt & Fabricius (* 4 versions), lettER, Nearey (*4 versions)",
    "linear compression or expansion (Fant, 1960), Gerstman, Lobanov"),

  "Approach" = c(
    "distance between means (Eucledian distance)",                    
    "variance reduction (visual inspection)",
    "distance between means, variance reduction (regression)",
    "variance reduction (regression)",
    "distance between means (F-statistics)",
    "variance reduction (visual inspection)",
    "variance reduction (SCV in talker-means)",
    "variance reduction (SCV in talker-means)",
    "distance between means"),

  "Best two performing" = c(
    "log-mean in linear regression framework (1), Nearey2 (2)",
    "Nearey, Watt & Fabricius, Gerstman, Lobanov (no order)",
                            "Sankoff (1)",
                            "Lobanov (1), Gerstman, Watt & Fabricius (2)",
                            "Sankoff (1), Nearey2 (2)",
                            "Nearey2 (1), Lobanov (2)",
                            "Lobanov (1), Watt & Fabricius (2)",
                            "Gerstman (1), LCE (2)",
                            "Lobanov (1), Gerstman (2)"))
```


```{r norm-evaluation-variability-SI, results='asis'}
norm_accounts_eval %>%
  kable(
    format = "latex",
    booktabs = TRUE,
    caption = "Previous studies comparing the effectiveness of normalization accounts in reducing within-category cue variability") %>%
  kable_styling(font_size = 7) %>%
  column_spec(1:2, width = "2cm") %>%
  column_spec(3, width = "5.5cm") %>%
  column_spec(4, width = "6cm") %>%
  column_spec(5:6, width = "2.5cm") %>%
  landscape() %>%
  collapse_rows()
```

<!--AP: this entire chunk is suggested to be moved to introduction by R2 (including the above table). Copied into main text for now: 
Table \@ref(tab:norm-evaluation-variability-SI) lists previous studies that have compared normalization accounts in terms of their effectiveness in reducing inter-talker variability. These studies varied in the specific metrics they employed to assess the effects of normalization, the languages they studied, and the conclusions they arrived at. Two generalizations emerge from Table \@ref(tab:norm-evaluation-variability-SI). First, transformation to a perceptual scale alone does not seem to be sufficient to reduce inter-talker variability [see also @adank2004; @carpenter1993; @clopper2009; @escudero2007; @Flynn2011; @kohn2012a]. Second, normalization accounts that include centering and/or standardizing seem to perform best in reducing inter-talker variability [see e.g. @barreda2018a; @disner1980; @fabricius2009; @kohn2012a; @labov2010; @lobanov1971]. When Lobanov and Gerstman normalization---both involving standardizing---were included in a study, they often rank among the top two performing accounts. Of note, Nearey normalization [@nearey1978] seems to perform well even though it does not involve the computationally more complex operation of standardizing. This suggests that simple centering of formants relative to the talker's mean *might* be sufficient to achieve significant variance reduction [but see @disner1980 for Swedish, which is revisited in this study].-->
<!-- Commented out for now as it doesn't seem critical. ^[Some studies have further investigated the extent to which different normalization accounts remove socially-relevant variance along with the intended removal of physiologically-caused variance [e.g., @adank2004; @disner1980; @hindle1978; @labov2010]. Removal of socially-relevant variance has been argued to be problematic for two separate reasons. First, for *researchers* who employ normalization as part of their data analysis, it can make it difficult to investigate the effects of social variables on pronunciation. Second, as a theory of how *listeners* overcome the lack of invariance in the speech signal, it has been argued to conflict with the finding that listeners infer social group membership from speech signal [@REFS]. Only this latter concern is of relevant for the present study, and---as others have pointed out---normalization does not necessarily mean that the raw input to normalization is discarded [@sumner2014; @OTHERS]. We thus do not further discuss this aspect.]  -->

## Methods {#sec:methodsI -}

### Speech materials {#sec:speechMaterialsI -}
This study employs the same speech materials as in the main study. Paralleling the main study, we evaluated category separability for each combination of normalization account, cues, and training-test fold. Specifically, we use the exact same cross-validation folds as in the main study.

### Separability index {#sec:separabilityIndex -}
<!--AP: moved from main paper-->
Previous studies have used different measures to assess the relative success of a normalization procedure in reducing inter-talker variability [see Table \@ref(tab:norm-evaluation-variability-SI) and @nearey1989 for an overview on classification accounts]. This includes assessing the reduction in variance or distance between means by visual inspection [e.g., @clopper2009; @disner1980; @hindle1978], or by calculating the reduction in within-category variance across talkers [e.g., @disner1980; @fabricius2009; @Flynn2011; @hindle1978], or comparing the degree of separation between category means for unnormalized and normalized data, i.e., an F-ratio [e.g., @labov2010].<!--AP: end here--> We will assess how distinguishable vowels become under different normalization accounts by calculating a separability index, as described in Equation \@ref(eq:separability-index). Following some previous studies [e.g., @labov2010], this separability index is essentially an F statistics, where the F statistics is the ratio of the within- and between-category variances:

\begin{equation}\label{eq:separability-index}
\begin{split}
 separability\ index &= \frac{between\ category\ MS}{within\ category\ MS}\\
 &= \frac{\sum\limits_{c=1,\ldots,K}(N_{c}-1)}{K-1}\frac{\sum\limits_{c=1,\ldots,K}(\bar{x}_{c}-\bar{x})^{2}}{\sum\limits_{c=1,\ldots,K} \sum\limits_{i=1,\ldots,N_{c}}(x_{i,c}-\bar{x}_{c})^{2}}
\end{split}
\end{equation}

where $K$ is the number of categories, $N_c$ is the number of observations for category $c$, $x_{i,c}$ is the cue vector (for all cues considered in the calculation of the separability index) for observation $i$ of category $c$, $\bar{x}_c$ is the cue mean vector for category $c$, and $\bar{x}$ is the overall cue mean vector. We calculated this separability index separately for each combination of normalization account, cues, and training-test fold, as described next.

## Results {-#sec:resultsI}

### Visualizing the distribution of vowel productions {#sec:normVowelSpace -}
Figures \@ref(fig:swe-vowels-normalized-long) and \@ref(fig:swe-vowels-normalized-short) visualize the Central Swedish vowels in the test data, after applying the 15 different scale-transformations and normalization accounts for a visual inspection. For this purpose, we focus on F1 and F2 only. The SI includes similar pairwise correlation plots of all cues for all different normalization accounts we compare (see [SI, Correlation matrices](#sec:correlation-matrices)). <!--AP: this ref needs adjusting, depending on whether some visualizations will be included in the main text.-->

Visual inspection suggests a few initial observations. The most striking difference is perhaps between intrinsic normalization accounts [@Syrdal1986; @miller1989c] and all other approaches, though it is not immediately visually obvious which type of approach achieves better separability. Second, transforming the vowels to a different perceptual scale does not seem to affect the vowel distributions much, besides a minor decrease in category variance for some of the vowels. Some transformations bring the vowel categories closer together, towards the center of the vowel space, e.g., ERB and semitones. Third, centering formants by subtracting each talkers' mean [@mcmurray-jongman2011; @nearey1978] reduces some of the category variance, and as a result, increases the category separability. Transforming the vowel data into different scales prior to centering also seems to further improve separability (compare e.g., C-CuRE (Hz) and C-CuRE (semitones)). Overall, the top two performing accounts across the long and short vowels appear to be @lobanov1971 and @nearey1978. However, even for the best performing normalization accounts, there is still considerable category overlap. This involves some of the high long vowels, and some of the mid-center short vowels. This highlights the need to more systematically quantify the effects of normalization, as we do next for category separability (and in more depth in the main study).<!--AP: check this wording.-->

(ref:swe-vowels-normalized-long) The 11 long vowels of Central Swedish when F1 and F2 are left unnormalized or transformed into a perceptual scales (**grey**), intrinsically normalized (**yellow**), or extrinsically normalized through centering (**blue**) or standardizing (**purple**). Each point corresponds to one recording, averaged across the five measurement points within each vowel segment. Each panel combines the data from all five test folds.

(ref:swe-vowels-normalized-short) The 10 short vowels of Central Swedish when F1 and F2 are left unnormalized or transformed into a perceptual scales (**grey**), intrinsically normalized (**yellow**), or extrinsically normalized through centering (**blue**) or standardizing (**purple**). Each point corresponds to one recording, averaged across the five measurement points within each vowel segment. Each panel combines the data from all five test folds.

```{r echo=FALSE}
#Store grob.element
element_textbox_highlight <- function(
    ...,
    hi.labels = NULL, hi.fill = NULL,
    hi.col = NULL, hi.box.col = NULL,
    hi.labels2 = NULL, hi.fill2 = NULL,
    hi.col2 = NULL, hi.box.col2 = NULL,
    hi.labels3 = NULL, hi.fill3 = NULL,
    hi.col3 = NULL, hi.box.col3 = NULL
) {
  structure(
    c(ggtext::element_textbox(...),
      list(hi.labels = hi.labels, hi.fill = hi.fill, hi.col = hi.col, hi.box.col = hi.box.col,
           hi.labels2 = hi.labels2, hi.fill2 = hi.fill2, hi.col2 = hi.col2, hi.box.col2 = hi.box.col2,
           hi.labels3 = hi.labels3, hi.fill3 = hi.fill3, hi.col3 = hi.col3, hi.box.col3 = hi.box.col3)),
    class = c("element_textbox_highlight", "element_textbox", "element_text", "element",
              "element_textbox_highlight", "element_textbox", "element_text", "element",
              "element_textbox_highlight", "element_textbox", "element_text", "element"))
}

element_grob.element_textbox_highlight <- function(element, label = "", ...) {
  if (label %in% element$hi.labels) {
    element$fill <- element$hi.fill %||% element$fill
    element$colour <- element$hi.col %||% element$colour
    element$box.colour <- element$hi.box.col %||% element$box.colour
  }
  if (label %in% element$hi.labels2) {
    element$fill <- element$hi.fill2 %||% element$fill
    element$colour <- element$hi.col2 %||% element$colour
    element$box.colour <- element$hi.box.col2 %||% element$box.colour
  }
  if (label %in% element$hi.labels3) {
    element$fill <- element$hi.fill3 %||% element$fill
    element$colour <- element$hi.col3 %||% element$colour
    element$box.colour <- element$hi.box.col3 %||% element$box.colour
  }
  NextMethod()
}

# Plot vowel data in all normalization formats
p.vowels.norm.long <-
  d.SwehVd.forStudy.long %>%
  # filter down to test folds since that's what we later evaluate SI and IOs for + the best performing SyrdalGopal
  filter(fold_type == "test", Quantity == "long", Normalization.Type != "SyrdalGopal2 (Bark)") %>%
  ggplot(
    aes(
      x = F2,
      y = F1)) +
  geom_point(
    aes(
      colour = category,
      shape = Quantity),
    alpha = 0.4,
    size = .7) +
  scale_colour_manual(name = "category", values = colors.vowel.swe) +
  scale_x_reverse("F2", position = "top", scales::pretty_breaks(n = 3)) +
  scale_y_reverse("F1", position = "right", scales::pretty_breaks(n = 3)) +
  guides(alpha = "none", color = "none", shape = "none") +
  facet_wrap(~ factor(Normalization.Type, levels = labels.normalization), scales = "free", ncol = 5) +
  theme(
    axis.title.y = element_blank()) +
    theme_half_open(12) +
    background_grid() +
    theme(
      strip.background = element_blank(),
      strip.text = element_textbox_highlight(
        size = 8,
        color = "black", fill = "#C9C0BB", box.color = "#C9C0BB",
        halign = 0.5, linetype = 1, r = unit(3, "pt"),
        #width = unit(1, "npc"),
        padding = margin(2, 3, 2, 3), margin = margin(3, 3, 3, 3),
        #margin = margin(0.6, 0.5, 0.5, 0.3),
        # this is new relative to element_textbox():
        # first named set
        hi.labels = c("SyrdalGopal (Bark)", "Miller (log)"),
        hi.fill = "#E6BE8A", hi.col = "black", hi.box.col = "#E6BE8A",
        # add second set
        hi.labels2 = c("C-CuRE (Hz)", "C-CuRE (Mel)", "C-CuRE (Bark)", "C-CuRE (ERB)", "C-CuRE (semitones)", "Nearey1 (log)", "Nearey2 (log)"),
        hi.fill2 = "#ABCDEF", hi.col2 = "black", hi.box.col2 = "#ABCDEF",
        # add third set
        hi.labels3 = c("Gerstman (Hz)", "Lobanov (Hz)"),
        hi.fill3 = "#DDADAF", hi.col3 = "black", hi.box.col3 = "#DDADAF"),
      axis.text.x = element_text(size=8, vjust=1),
      axis.text.y = element_text(size=8, hjust=1, vjust=.5),
      axis.title.x = element_text(size=8, vjust=0, hjust=0.5, face = "bold"),
      axis.title.y = element_text(size=8, hjust= 0.5, vjust=0.5, face = "bold"),
      legend.title = element_text(size=8, face = "bold", hjust= 0),
      legend.text = element_text(size=8),
      strip.placement = "outside",
      aspect.ratio = 1,
      panel.grid.major = element_blank())
```

\begin{landscape}

```{r swe-vowels-normalized-long, fig.width=base.width * 4, fig.height=base.height * 3, fig.align='center', out.width='90%', fig.cap="(ref:swe-vowels-normalized-long)"}
p.vowels.norm.long
```

\end{landscape}

```{r echo=FALSE}
# Plot vowel data in all normalization formats
p.vowels.norm.short <- p.vowels.norm.long %+%
  (d.SwehVd.forStudy.long %>%
     #Filter down to test data, and to the best performing implementation of Syrdal&Gopal
     filter(fold_type == "test", Quantity == "short", Normalization.Type != "SyrdalGopal2 (Bark)")) +
  geom_point(aes(color = category),
             shape = 17,
             alpha = .4,
             size = .7)
```

\begin{landscape}
```{r swe-vowels-normalized-short, fig.width=base.width * 4, fig.height=base.height * 3, fig.align='center', out.width='90%', fig.cap="(ref:swe-vowels-normalized-short)"}
p.vowels.norm.short
```

\end{landscape}

### The effect of normalization accounts on the variability of Central Swedish vowels {#sec:normVariability -}
In order to assess the effects of normalization accounts on category separability, we calculate a separability index under different assumptions about the relevant cues and the size of the vowel space (the long and short vowels separately, or the entire space). Before we evaluate how category separability is affected by normalization in F1-F2, F1-F3, and F0-F3 and duration space, we look at how the normalization accounts affect the separability of vowels along each cue separately (Figure \@ref(fig:separability-by-cue)). As we show below, this is helpful in understanding the subsequently presented results for combinations of cues.

```{r}
cues <- c("F0", "F1", "F2", "F3", "Duration")

# Calculate a separability index for all categories and all normalization accounts.
# First get within-category means
d.SwehVd.forStudy.long.within_category_MS <-
  d.SwehVd.forStudy.long %>%
  # Reduce to test fold of each crossvalidation group since that's what we want to know SI for
  filter(fold_type == "test") %>%
  # Get within category MS and pseudo-MS
  group_by(Normalization.Type, category, crossvalidation_group, fold_type, fold) %>%
  summarise(
    # First obtain df and SS for each cues
    across(
      .cols = cues,
      .fns = list(
        "within_df" = ~ if (sum(!is.na(.x)) == 0) { NA } else { sum(!is.na(.x)) - 1}, # Set cases with 0 DFs to NA (happens when cue is not defined for a normalization type)
        "category_mean" = ~ mean(.x, na.rm = T)),
      .names = "{.fn}_{.col}"),
    across(
      .cols = cues,
      .fns = list("within_SS" = ~ if (sum(!is.na(.x)) == 0) { NA } else { sum((.x - get(glue("category_mean_{cur_column()}")))^2, na.rm = T) }),
      .names = "{.fn}_{.col}"),
    # Now get all the measures *across* cues
    within_df_F1F2 = pmin(within_df_F1, within_df_F2),
    within_df_F1F3 = pmin(within_df_F1, within_df_F2, within_df_F3),
    within_df_F0F3 = pmin(within_df_F0, within_df_F1, within_df_F2, within_df_F3),
    within_df_all = pmin(within_df_F0, within_df_F1, within_df_F2, within_df_F3, within_df_Duration),
    within_SS_F1F2 = within_SS_F1 + within_SS_F2,
    within_SS_F1F3 = within_SS_F1 + within_SS_F2 + within_SS_F3,
    within_SS_F0F3 = within_SS_F0 + within_SS_F1 + within_SS_F2 + within_SS_F3,
    within_SS_all = within_SS_F0 + within_SS_F1 + within_SS_F2 + within_SS_F3 + within_SS_Duration,
    # Get within-category MS
    across(
      .cols = paste0("within_SS_", c(cues, "F1F2", "F1F3", "all")),
      .fns = list("pseudo_within_MS" = ~ .x / get(glue(gsub("within_SS_", "within_df_", cur_column())))),
      .names = "{.fn}_{.col}")) %>%
  rename_with(~ gsub("_within_SS", "", .x))
```

```{r}
get_SI <-
  . %>%
  group_by(Normalization.Type, crossvalidation_group) %>%
  summarise(
    across(
      .cols = paste0("within_SS_", c(cues, "F1F2", "F1F3", "all")),
      .fns = list("within_MS" = ~ sum(.x, na.rm = T) / sum(get(glue(gsub("within_SS_", "within_df_", cur_column()))), na.rm = T)),
      .names = "{.fn}_{.col}")) %>%
  rename_with(~ gsub("_within_SS", "", .x)) %>%
  left_join(
    d.SwehVd.forStudy.long %>%
      # Get overall mean within each normalization approach
      group_by(Normalization.Type, crossvalidation_group) %>%
      mutate(
        across(
          .cols = cues,
          .fns = list("overall_mean" = ~ mean(.x, na.rm = T)),
          .names = "{.fn}_{.col}")) %>%
      group_by(Normalization.Type, category, crossvalidation_group) %>%
      # Get category means and carry through overall mean
      summarise(
        across(
          .cols = paste0("overall_mean_", cues),
          first),
        across(
          .cols = cues,
          .fns = list("category_mean" = ~ mean(.x, na.rm = T)),
          .names = "{.fn}_{.col}")) %>%
      # Get between-category SS and MS
      group_by(Normalization.Type, crossvalidation_group) %>%
      summarise(
        # First obtain df and SS for each cues
        across(
          .cols = paste0("category_mean_", cues),
          .fns = list(
            "between_df" = ~ if (sum(!is.na(.x)) == 0) { NA } else { sum(!is.na(.x)) - 1},  # Set cases with 0 DFs to NA (happens when cue is not defined for a normalization type)
            "between_SS" = ~ if (sum(!is.na(.x)) == 0) { NA } else { sum((.x - get(glue(gsub("category_mean", "overall_mean", cur_column()))))^2, na.rm = T) }),
          .names = "{.fn}_{.col}"),
        # Now get all the measures *across* cues
        between_df_category_mean_F1F2 = pmin(between_df_category_mean_F1, between_df_category_mean_F2),
        between_df_category_mean_F1F3 = pmin(between_df_category_mean_F1, between_df_category_mean_F2, between_df_category_mean_F3),
        between_df_category_mean_F0F3 = pmin(between_df_category_mean_F0, between_df_category_mean_F1, between_df_category_mean_F2, between_df_category_mean_F3),
        between_df_category_mean_all = pmin(between_df_category_mean_F0, between_df_category_mean_F1, between_df_category_mean_F2, between_df_category_mean_F3, between_df_category_mean_Duration),
        between_SS_category_mean_F1F2 = between_SS_category_mean_F1 + between_SS_category_mean_F2,
        between_SS_category_mean_F1F3 = between_SS_category_mean_F1 + between_SS_category_mean_F2 + between_SS_category_mean_F3,
        between_SS_category_mean_F0F3 = between_SS_category_mean_F0 + between_SS_category_mean_F1 + between_SS_category_mean_F2 + between_SS_category_mean_F3,
        between_SS_category_mean_all = between_SS_category_mean_F0 + between_SS_category_mean_F1 + between_SS_category_mean_F2 + between_SS_category_mean_F3 + between_SS_category_mean_Duration,
        # Get between-category MS
        across(
          .cols = paste0("between_SS_category_mean_", c(cues, "F1F2", "F1F3", "all")),
          .fns = list("between_MS" = ~ sum(.x / get(glue(gsub("between_SS", "between_df", cur_column()))))),
          .names = "{.fn}_{.col}")) %>%
      rename_with(~ gsub("(_between_SS)?_category_mean", "", .x)),
        by = c("Normalization.Type", "crossvalidation_group")) %>%
  # Now get the separability index
  group_by(Normalization.Type, crossvalidation_group) %>%
  mutate(
    across(
      .cols = paste0("between_MS_", c(cues, "F1F2", "F1F3", "all")),
      .fns = list("SI" = ~ sum(.x / get(glue(gsub("between_", "within_", cur_column()))))),
      .names = "{.fn}_{.col}")) %>%
  rename_with(~ gsub("_between_MS", "", .x)) %>%
  mutate_if(is.numeric, round, digits = 4)

d.SwehVd.forStudy.SI <- rbind(
  d.SwehVd.forStudy.long.within_category_MS %>%
    filter(category %in% levels.vowel.IPA.swe.long) %>%
    get_SI() %>%
    mutate(
      Quantity = "long vowels"),
  d.SwehVd.forStudy.long.within_category_MS %>%
    filter(category %in% levels.vowel.IPA.swe.short) %>%
    get_SI() %>%
    mutate(
      Quantity = "short vowels"),
  d.SwehVd.forStudy.long.within_category_MS %>%
    get_SI() %>%
    mutate(
      Quantity = "all vowels"))

d.SwehVd.forStudy.SI.long <-
  d.SwehVd.forStudy.SI %>%
  # include all separate SIs
  select(c(Normalization.Type, crossvalidation_group, Quantity, SI_F1F2, SI_F1F3, SI_Duration, SI_F0, SI_F1, SI_F2, SI_F3, SI_all)) %>%
  pivot_longer(
    cols = starts_with("SI_", ignore.case = FALSE),
    names_to = c("SI", "Cues"),
    names_sep = "_",
    values_to = "Cue.Value") %>%
  pivot_wider(
    names_from = "SI",
    values_from = "Cue.Value")
```

```{r}
plot_separability <- function(data) {
  data %>%
    ggplot(
    aes(x = Normalization.Type,
        y = SI,
        color = Normalization.Type)) +
  stat_summary(
     fun.data = mean_cl_boot,
     geom = "linerange") +
  stat_summary(
    fun.y = mean,
    geom = "label",
    aes(label = signif(..y..,2),
        x = as.integer(Normalization.Type)),
    size = 2.7, label.size = 0, label.padding = unit(0.05, "lines")) +
  scale_colour_manual(
    labels = labels.normalization.1SG,
    values = colors.all.procedures.1SG) +
  scale_y_continuous("Separability index (F-value)") +
  myGplot.defaults(base_size + 2) +
  theme(
    axis.text.x = ggtext::element_markdown(angle = 60, vjust = 1, hjust=1, colour = colors.all.procedures.1SG),
    axis.title.x = element_blank(),
    aspect.ratio = 3/6) +
  guides(color = "none")
}

p.separability.by_cue <- plot_separability(d.SwehVd.forStudy.SI.long %>%
                                             #Filter down to best performing implementation of Syrdal&Gopal
                                             filter(Cues %in% c("F0", "F1", "F2", "F3", "Duration"), Normalization.Type != "SyrdalGopal2 (Bark)") %>%
                                             mutate(Normalization.Type = factor(plyr::mapvalues(Normalization.Type, levels.normalization.1SG, labels.normalization.1SG), levels = labels.normalization.1SG, ordered = T))) +
  facet_grid(factor(Cues, levels = c("F1", "F2", "F3", "F0", "Duration"), labels = c("F1", "F2", "F3", "F0", "duration")) ~ factor(Quantity, levels = c("long vowels", "short vowels", "all vowels")), scales = "free_y")
```

(ref:separability-by-cue) Separability indices by normalization accounts for long vowels, short vowels, and all vowels together (columns), shown for each of the five cues considered in this study (rows). Labels indicate mean across the five test folds. Intervals show average bootstrapped 95% confidence intervals across the test folds. Note that the ranges of the y-axes varies across plots.

```{r separability-by-cue, fig.width=base.width * 4.5, fig.height=base.height * 5.5, fig.align='center', out.width='100%', fig.cap="(ref:separability-by-cue)"}
p.separability.by_cue
```

For F1 (first row of Figure \@ref(fig:separability-by-cue)), we see a clear advantage for centering (in blue) and standardizing (in purple) compared to transformations (in grey) and intrinsic accounts (in yellow). In particular Lobanov normalization seems to maximize category separability along F1, at least for the long vowels and all vowels together. Notably, the accounts pattern differently along F2 (second row of Figure \@ref(fig:separability-by-cue)). Overall, differences between accounts are much smaller along F2, and the clear advantage of centering and standardizing accounts along F1 does not extend to F2.

An altogether different picture is observed for F3. Compared to F1 and F2, the intrinsic account (Miller) performs substantially better in separating categories along F3, while all other accounts perform poorly. This result is surprising: one of the downsides of intrinsic approaches that has been noted in previous work is their sensitivity to measurement error [@thomas2007]. This sensitivity is caused by the fact that intrinsic accounts use a single measurement for normalization, rather than the less noisy estimates resulting from aggregating across segments that are used in extrinsic accounts. Since the third formant is often described as more difficult to reliably estimate than other formants (leading to more measurement error), F3 would be expected to be particularly affected by this weakness of intrinsic accounts.

Yet, further visualization in Figure \@ref(fig:F3-densities) confirms that F3 indeed separates categories particularly well when intrinsic normalization is applied. Compared to other accounts, @miller1989c seems to be particularly successful in separating vowels that differ in lip rounding. For example, @miller1989c separates two clusters among the high and mid-high vowels, one consisting of the back vowels `r linguisticsdown::cond_cmpl("[oː]")` and `r linguisticsdown::cond_cmpl("[uː]")`, and the other one of the front `r linguisticsdown::cond_cmpl("[iː]")`, and rounded `r linguisticsdown::cond_cmpl("[yː]")` and `r linguisticsdown::cond_cmpl("[ʉː]")`. One possible explanation for this result is that intrinsic normalization is indeed particularly effective for F3, and that our correction of measurement errors---equally applied to all formants---effectively reduced the issue with F3 measurement errors (presumably the human brain, too, can do better than an uncorrected Praat algorithm without error correction). As we show below, this result for F3 carries over to any combination of cues that includes F3. It is, however, an artifact of using category separability to assess the effectiveness of normalization, as we show in the main study. We elaborate on this issue in the discussion further down.

Returning to Figure \@ref(fig:separability-by-cue), normalization does not increase category separability for F0. This is expected given that F0 is known to affect vowel separability primarily through its indirect influence on the interpretation of other formants [e.g., @barreda2012a; @barreda2020a]. Finally, for duration all of the C-CuRE accounts group together against the remaining accounts. This, too, is expected since all other accounts are formant-specific and thus do not normalize duration. In summary, the five cues contribute to category separability in different ways, and this is reflected in varying effectiveness of different normalization accounts. We also note that the best performing normalization account for any combination of cues and vowel qualities is typically never significantly better than the next best performing model (the 95% confidence intervals of the best model overlap with the mean of the next best model). In fact, for many combinations of cues and vowel qualities, many of the models perform similarly.

(ref:F3-densities) Category densities along F3 illustrates the effectiveness of vowel-intrinsic normalization for this cue. Here shown for Miller, compared to vowel-extrinsic accounts that center and/or standardize cues. For reference, densities in the absence of normalization are also shown.

```{r F3-densities, fig.width= base.width * 4, fig.height = base.height * 2.5, fig.align='center', out.width='95%', fig.cap="(ref:F3-densities)"}
# Generate list of manual y-scale limits, in order to have category labels fit in at density tops
scales <- list(
  # Specify all the scales, one for each facet
  scale_y_continuous(limits = c(0,.003)),
  scale_y_continuous(limits = c(0,8)),
  scale_y_continuous(limits = c(0, .004)),
  scale_y_continuous(limits = c(0,1)),
  scale_y_continuous(limits = c(0,.003)),
  scale_y_continuous(limits = c(0,10)),
  scale_y_continuous(limits = c(0, .003)),
  scale_y_continuous(limits = c(0,.8))
)

d.SwehVd.forStudy.long %>%
  filter(fold_type == "test", Normalization.Type %in% c("no normalization (Hz)", "Miller (log)", "C-CuRE (Hz)", "Lobanov (Hz)")) %>%
  ggplot(
    aes(F3, fill = factor(category))) +
  geom_density(alpha = .5) +
  geomtextpath::geom_textdensity(aes(label = category),
                                 size = 3,
                                 hjust = "ymax",
                                 vjust = -0.5, text_only = T, straight = T) +
  theme(legend.position = "none") +
  scale_colour_manual(name = "category", values = colors.vowel.swe, aesthetics = c("colour", "fill")) +
  guides(linetype = "none", color = "none", fill = "none") +
  ggh4x::facet_grid2(factor(Quantity, levels = c("long", "short"), labels = c("long vowels", "short vowels")) ~ Normalization.Type, scales = "free", independent = "all") +
  ggh4x::facetted_pos_scales(y = scales)
```

Next, we summarize how normalization affects category separability when combinations of the fives cues are considered. Figure \@ref(fig:separability) shows the separability index for the different normalization accounts for three different combinations of cues. For the first row of Figure \@ref(fig:separability), we followed most previous research in assessing category separability for the combination of F1 and F2 [e.g., @disner1980; @fabricius2009; @Flynn2011; @hindle1978; @labov2010]. Accounts that center against the talker's overall formant mean (in blue) are among the best performing normalization accounts. No matter the assumed perceptual scale, centering always improves category separability. Standardizing accounts (in purple), primarily @lobanov1971, also perform well at separating categories, more so for the long vowels. However, scale transformations (in grey), and intrinsic accounts (in yellow), do not improve category separability compared to unnormalized Hz, at least not when assessed on the long vowels or the entire vowel space. 

The remaining rows of Figure \@ref(fig:separability) compare normalization accounts when F3 (second row) or F0, F3, and duration are included (third row). Overall, the category separability is now lower, a result of how the accounts affect category separability along the cues added (see Figure \@ref(fig:separability-by-cue)). The most drastic change in performance concerns the intrinsic @miller1989c and the standardizing accounts. When including F3, @miller1989c performs as well or better, in absolute numbers, as when evaluated on only the combination of F1 and F2, thereby increasing its performance relative to other accounts. This increase in performance might be particularly pronounced for languages like Swedish, where F3 carries important information about lip rounding and thus vowel identity. In contrast, performance of standardizing accounts drops substantially if F3 or any other cue besides F1 and F2 is included.^[We confirmed this by conducting additional comparisons using only F1, F2 and F0, or only F1, F2 and duration. For both of these comparisons too, we found that standardizing accounts perform poorly.] This mirrors what was found when assessing category separability separately for each cue (Figure \@ref(fig:separability-by-cue)).

Finally, looking across all three rows, category separability is consistently higher for short than long vowels. The same pattern is evident for each cue separately in Figure \@ref(fig:separability-by-cue). This result conceptually replicates an initially surprising result of the main study: while short vowels are more densely clustered in the center of the vowel space, and thus occupy a smaller perceptual space, they also exhibit less category variability and less category overlap, making them overall more separable.

```{r}
#"F1F2", "F1F3", "F0F3", "F0F2", "all", "allNOF0", "allNOF3"
p.separability <- plot_separability(d.SwehVd.forStudy.SI.long %>%
                                            #Filter down to test data, and to the best performing implementation of Syrdal&Gopal
                                             filter(Cues %in% c("F1F2", "F1F3", "all"), Normalization.Type != "SyrdalGopal2 (Bark)") %>%
                                             mutate(Normalization.Type = factor(plyr::mapvalues(Normalization.Type, levels.normalization.1SG, labels.normalization.1SG), levels = labels.normalization.1SG, ordered = T))) +
  facet_grid(factor(Cues, levels = c("F1F2", "F1F3", "all"), labels = c("F1-F2", "F1-F3", "F0-F3, duration")) ~ factor(Quantity, levels = c("long vowels", "short vowels", "all vowels")), scales = "free_y")
```

(ref:separability) Separability indices by normalization accounts for long vowels, short vowels, and both long and short vowels together (columns) shown for three different combinations of cues (rows). Labels indicate mean across the five test folds. Intervals show average bootstrapped 95% confidence intervals across the test folds. Note that the ranges of the y-axes varies across plots.

```{r separability, fig.width= base.width * 4, fig.height = base.height * 3, fig.align='center', out.width='100%', fig.cap="(ref:separability)"}
plot_grid(NULL, p.separability, rel_widths = c(.01, 1))
```

## Discussion {#sec:studyI-discussion -}
When only F1 and F2 are considered, as in most previous work on vowel normalization, we find that extrinsic centering and standardizing accounts achieve the best category separability. Within these two types of accounts, there is considerable variability. For example, among the intrinsic accounts, Miller performs worse than Syrdal & Gopal, among the extrinsic accounts, versions of C-CuRE seem to consistently perform best. It is also worth noting, however, that there is never a single account that performs significantly better than all other normalizations. This points to the inherent similarities across normalization accounts, and perhaps limitations of the approach taken here (and in some previous work). This point is also raised in the general discussion in the main paper. Regardless of these caveats, the findings for F1 and F2 in this additional study, revise the results of @disner1980 for Swedish, and instead replicates previous findings for the other Germanic languages in Disner's sample as well as the majority of previous studies on other languages [e.g., @fabricius2009; @Flynn2011; @labov2010]. 

However, when F3 is considered along with F1 and F2, this result does no longer hold. Key to understanding this result and what it says about the suitability of category separability as a measure of normalization accounts is Figure \@ref(fig:separability-by-cue): while extrinsic normalization performs better than other approaches for F1 and F2, the absolute differences in performance are small compared to the advantage of the intrinsic account observed for F3. Combined with a seemingly innocuous aspect of the separability index in Equation \@ref(eq:separability-index), this allows separability along F3 to dominate separability along the other cue dimensions. Our separability index takes the *sum* of (squared) distances along each cue dimension, essentially assuming that the effect of all cues is simply a sum of each cue's effect considered separately. This means that the separability index cannot capture the *joint* effect of cues---whether, for example, one cue effectively separates one set of categories and another cue separates another set of categories, rather than both cues separating the same categories. The separability index thus cannot recognize, for example, that F1 and F2 capture largely complementary aspects of the vowel inventory (as evident in, for example, Figures \@ref(fig:swe-vowels-normalized-long) and \@ref(fig:swe-vowels-normalized-short)).

This is not the only deficiency of the separability index or similar measures of category variability. The use of *squared* distances means that even a small number of observations located far away from the category mean can disproportionally affect the index. Consider, for example, the F3 densities in Figure \@ref(fig:F3-densities). For non-intrinsic normalizations, some categories have low but non-zero densities far away from the mode. Because of the use of squared distances, this results in low category separability for these normalization accounts despite the fact that observations with such cue values are rare and thus not expected to have a large effect on the *average* perceptual separability of vowels. For the same reason (the use of squared distances), category separability can be high even if a cue separates only a small subset of categories (as is the case for F3), compared to another cue that more gradiently separates *all* categories (as is the case for F1 and F2; see Figure \@ref(fig:swe-vowels-all-cues)).

Finally, measures like the separability index suffer from a conceptual issue: the goal of speech perception is presumably not to reduce cue variability around the category mean but rather to increase the probability of correct recognition (of both linguistic and social information, where we focus on the former here). These two goals are not the same [see also discussion in @barreda2020a]. In sum, indices of variability and category separability like that in Equation \@ref(eq:separability-index) fail to adequately assess the expected consequences of normalization for perception, which is the primary interest of this paper, and addressed by the adopted methodology in the main study.

# Evaluation of implementations of Syrdal & Gopal's (1986) second dimension {#sec:SG-eval -}
For the second dimension, distinguishing between front and back vowels, @Syrdal1986 evaluates two different bark-difference measures: F2-F1 and F3-F2. Previous studies had concluded that F2-F1 distinguishes between all Swedish vowels [@fant1983], however, in @Syrdal1986's evaluation of American English, the F3-F2 dimension provided a better fit. Given that there seems to be language specific effects concerning @Syrdal1986's second dimension [e.g., @adank2003], here we compare the two difference measures for the vowels in the SwehVd database.

```{r}
levels.norm.SG <- c("Bark_SyrdalGopal", "Bark_SyrdalGopal2")
labels.norm.SG <-  c("SyrdalGopal (Bark)", "SyrdalGopal2 (Bark)")
levels.norm.plots.SG <- c("SyrdalGopal_Bark", "SyrdalGopal2_Bark")
p.separability.by_cue.SG <- plot_separability(d.SwehVd.forStudy.SI.long %>%
                                             filter(Cues %in% c("F0", "F1", "F2", "Duration", "F1F2"), Normalization.Type %in% c("SyrdalGopal (Bark)", "SyrdalGopal2 (Bark)")) %>%
                                             mutate(Normalization.Type = factor(plyr::mapvalues(Normalization.Type, levels.norm.SG, labels.norm.SG), levels = labels.norm.SG, ordered = T))) +
  scale_colour_manual(values =  c("#E6BE8A", "#E6BE8A")) +
  theme(
    axis.text.x = ggtext::element_markdown(angle = 60, vjust = 1, hjust=1, colour = "#E6BE8A")) +
  facet_grid(factor(Cues, levels = c("F1", "F2", "F0", "Duration", "F1F2"), labels = c("F1", "F2", "F0", "duration", "F1F2")) ~ factor(Quantity, levels = c("long vowels", "short vowels", "all vowels")), scales = "free_y")
```

(ref:separability-by-cue-SG) Separability indices of the two versions of the Syrdal & Gopal (1986) account for long vowels, short vowels, and long and short vowels together, shown for four of the five cues considered in this study and the combined F1-F2. Labels indicate mean across the five test folds. Intervals show average bootstrapped 95% confidence intervals across the test folds. Note that the ranges of the y-axes varies across plots.

Figure \@ref(fig:separability-by-cue-SG) displays the separability index for the two implementations. The first version uses the F2-F1 bark-difference metric for the second dimension, whereas the second version (labelled *SyrdalGopal2 (Bark)*) implements the second dimension as suggested by @Syrdal1986, F3-F2. As evident from Figure \@ref(fig:separability-by-cue-SG), the first implementation performs better at separating categories in the SwehVd data, which replicates @fant1983.

```{r separability-by-cue-SG, fig.width=base.width * 4, fig.height=base.height * 5.5, fig.align='center', out.height='90%', fig.cap="(ref:separability-by-cue-SG)"}
p.separability.by_cue.SG
```

```{r}
# Make talker-independent IOs on long and short vowels *separately*, for different cue combinations
m.io.SwehVd.F1F2_by_quantity.SG <-
  make_IOs_and_add_test_data(
    data = d.SwehVd.forStudy.long %>%
      filter(Normalization.Type %in% c("SyrdalGopal (Bark)", "SyrdalGopal2 (Bark)")),
    cues = c("F1", "F2"),
    separate_by = c("Quantity")) %>%
  mutate(IO.cue_normalization = ifelse(is.na(IO.cue_normalization), "SyrdalGopal2", "SyrdalGopal"))

# Make talker-independent IOs on long and short vowels *combined*, for different cue combinations
m.io.SwehVd.F1F2.SG <-
  make_IOs_and_add_test_data(
    data = d.SwehVd.forStudy.long %>%
      filter(Normalization.Type %in% c("SyrdalGopal (Bark)", "SyrdalGopal2 (Bark)")),
    cues = c("F1", "F2")) %>%
  # Add column for plotting
  mutate(
    IO.Quantity = "all",
    IO.cue_normalization = ifelse(is.na(IO.cue_normalization), "SyrdalGopal2", "SyrdalGopal"))

#Make combined dataframe for plotting
m.io.SwehVd.SG <- rbind(
  m.io.SwehVd.F1F2_by_quantity.SG %>%
    mutate(Cue_space = "F1-F2"),
  m.io.SwehVd.F1F2.SG %>%
    mutate(Cue_space = "F1-F2")) %>%
  mutate(Cue_space = factor(Cue_space, levels = c("F1-F2", "F1-F3", "F0-F3, duration")))

p.accuracy.io.overall.SG <- plot_io_results(m.io.SwehVd.SG) + facet_grid(Cue_space ~ factor(IO.Quantity, levels = c("long", "short", "all"), labels = c("long vowels", "short vowels", "all vowels"))) +
  scale_colour_manual(values =  c("#E6BE8A", "#E6BE8A")) +
  theme(
    axis.text.x = ggtext::element_markdown(angle = 60, vjust = 1, hjust=1, colour = "#E6BE8A"))
```
(ref:accuracy-SG) Predicted recognition accuracy of ideal observer under two versions of the Syrdal & Gopal (1986) account for long vowels, short vowels, and long and short vowels together, shown for the F1-F2 cue combination. Labels indicate mean across the five test folds. Intervals show average bootstrapped 95% confidence intervals across the test folds. The dashed horizontal line indicates chance (different across columns because of the different number of long and short vowels).

```{r accuracy-SG, fig.width=base.width * 5, fig.height=base.height * 2, out.width='90%', fig.align='center', fig.cap="(ref:accuracy-SG)"}
p.accuracy.io.overall.SG
```

We also evaluated the two Syrdal & Gopal implementations in terms of model predictions for perception. Figure \@ref(fig:accuracy-SG) displays the categorization accuracy for models trained on normalized data under the two implementations of the Syrdal & Gopal account. Mirroring the results from the separability index, the first implementation using F2-F1 for the second dimension, outperforms the implementation using F3-F2 bark-difference measure. These results taken together indicate that the F2-F1 implementation is more suitable for the materials used here, we therefore decided to use the first implementation throughout this paper.

# Correlation matrices for all normalization accounts {#sec:correlation-matrices -}
Here we include correlation matrices for the SwehVd vowel data, transformed into the 15 different normalization spaces.

\newpage

(ref:correlation-matrix-Mel) The SwehVd vowel data in Mel space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-Mel, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-Mel)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "transformed (Mel)"))
```

(ref:correlation-matrix-Bark) The SwehVd vowel data in Bark space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-Bark, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-Bark)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "transformed (Bark)"))
```

(ref:correlation-matrix-ERB) The SwehVd vowel data in ERB space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ERB, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ERB)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "transformed (ERB)"))
```

(ref:correlation-matrix-semitones) The SwehVd vowel data in semitones space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-semitones, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-semitones)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "transformed (semitones)"))
```

(ref:correlation-matrix-syrdalgopal) The SwehVd vowel data in SyrdalGopal (Bark) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-syrdalgopal, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-syrdalgopal)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "SyrdalGopal (Bark)"))
```

(ref:correlation-matrix-miller) The SwehVd vowel data in Miller (log) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-miller, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-miller)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "Miller (log)"))
```
(ref:correlation-matrix-ccure-hz) The SwehVd vowel data in C-CuRE Hz space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ccure-hz, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ccure-hz)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "C-CuRE (Hz)"))
```

(ref:correlation-matrix-ccure-mel) The SwehVd vowel data in C-CuRE Mel space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ccure-mel, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ccure-mel)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "C-CuRE (Mel)"))
```

(ref:correlation-matrix-ccure-bark) The SwehVd vowel data in C-CuRE Bark space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ccure-bark, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ccure-bark)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "C-CuRE (Bark)"))
```

(ref:correlation-matrix-ccure-erb) The SwehVd vowel data in C-CuRE ERB space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ccure-erb, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ccure-erb)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "C-CuRE (ERB)"))
```

(ref:correlation-matrix-ccure-semitones) The SwehVd vowel data in C-CuRE semitones space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-ccure-semitones, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-ccure-semitones)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "C-CuRE (semitones)"))
```

(ref:correlation-matrix-nearey1) The SwehVd vowel data in Nearey1 (log) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-nearey1, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-nearey1)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "Nearey1 (log)"))
```

(ref:correlation-matrix-nearey2) The SwehVd vowel data in Nearey2 (log) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-nearey2, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-nearey2)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "Nearey2 (log)"))
```

(ref:correlation-matrix-gerstman) The SwehVd vowel data in Gerstman (Hz) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-gerstman, fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-gerstman)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "Gerstman (Hz)"))
```

(ref:correlation-matrix-lobanov) The SwehVd vowel data in Lobanov (Hz) space. Points show repetitions of each of the 21 Central Swedish vowels by 16 female native talkers in the database in F0-F3 and vowel duration cue space. Vowel labels indicate category means across talkers. Long vowels are boldfaced. Ellipses show bivariate Gaussian 95% confidence interval of category means.

```{r correlation-matrix-lobanov,fig.width=base.width*3.5, fig.height=base.height*3.5+.5, out.width = '100%', fig.cap="(ref:correlation-matrix-lobanov)"}
p.matrix.cues %+%
  (d.SwehVd.forStudy.long %>%
  filter(fold_type == "test" & Normalization.Type == "Lobanov (Hz)"))
```

\newpage
