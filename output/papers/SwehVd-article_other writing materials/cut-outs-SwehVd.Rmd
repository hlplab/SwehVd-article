---
title: "SwehVd cut-outs"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview
This document contains cut-outs from the SwehVd-article, that might come of use.

# Distributional properties {#sec:distrProp}
In order to further investigate what might be driving the differences in performance of normalization accounts in terms of reducing inter-talker variability, we conduct a number of follow-up analyses that describe how different distributional properties of the data might affect category separability. One such property is the number of outliers introduced by the different normalization accounts, and to what extent that is more or less than what could be expected. The outlier percentage can also be informative of the degree to which these accounts overfit to the data. For approaches that use talker-specific cue parameters for normalization, listeners must have estimated these based on the tokens they have heard. Means and variances thus need to be inferred. Our training-test data split can be seen as simulating a situation where a listener is exposed to 80% of a talker's speech, and evaluate how s/he will categorize the next 20 tokens, based on previous exposure. If a given account generates an unusually high proportion of outliers, it can point to an overly narrow mean and overly small variance introduced by normalizing. Thereby indicating that it might not constitute a plausible cognitive model of human speech perception. To follow up, we also investigate differences in by-talker means and by-talker variances introduced by the different accounts.

```{r echo=FALSE}
# Determining outliers for test-folds only since that's the only data that will be used to evaluate
# the different approaches in terms of SI (here) and IOs (Study 2)
d.outliers <-
  d.SwehVd.forStudy.long %>%
  filter(fold_type == "test") %>%
  select(-crossvalidation_group) %>%
  filter(!is.na(F0)) %>%
  obtain_densities_allCues() %>%
  obtain_densities_Norm() %>%
  mutate(
    outlier_F1F2 = ifelse(is_outlier(cumulative_probability_F1F2), TRUE, FALSE),
    outlier_allCues = ifelse(is_outlier(cumulative_probability_allCues), TRUE, FALSE))

d.outliers.sum.F1F2 <- d.outliers %>%
  group_by(Normalization.Type, outlier_F1F2, category) %>%
  tally() %>%
  pivot_wider(names_from = outlier_F1F2, values_from = n) %>%
  rename(outlier_F = "FALSE", outlier_N = "TRUE") %>%
  group_by(Normalization.Type, category) %>%
  mutate(
    outlier_N = ifelse(is.na(outlier_N), 0, outlier_N),
    outliers_prop = outlier_N / sum(outlier_F + outlier_N) * 100)
d.outliers.sum.allCues <- d.outliers %>%
  group_by(Normalization.Type, outlier_allCues, category) %>%
  tally() %>%
  pivot_wider(names_from = outlier_allCues, values_from = n) %>%
  rename(outlier_F = "FALSE", outlier_N = "TRUE") %>%
  group_by(Normalization.Type, category) %>%
  mutate(
    outlier_N = ifelse(is.na(outlier_N), 0, outlier_N),
    outliers_prop = outlier_N / sum(outlier_F + outlier_N) * 100)
```

For distributional outliers, we used the same approach as for identifying measurement errors, that is, estimated the joint multivariate distribution along the first three formants and duration for each combination of vowel and talker. We identified all data points outside of the `r 100 * (outlier_probability_cutoff/2)`th to `r 100 * (1 - outlier_probability_cutoff/2)`th quantiles separately for each normalization space, and evaluated whether the normalization formulas affected the number of outliers excluded (see Figure \@ref(fig:swe-vowels-outliers)). Figure \@ref(fig:swe-vowels-outliers) summarises for each vowel, the data that would be excluded under different normalization accounts. Two general observations can be made. Some vowels are more prone to generate outliers than others, across accounts. Furthermore, some accounts seem to introduce a disproportionate amount of outliers.

Overall, the different vowel spaces seem to introduce approximately the same proportion of outliers, except for @Syrdal1986 and @miller1989c. Across normalization spaces, the different accounts generated mean(N)=`r d.outliers.sum.F1F2 %>% group_by(Normalization.Type) %>% summarise(outlier_N = sum(outlier_N)) %>% summarise(mean(outlier_N)) %>% pull() %>% round(digits = 1)` (SD =`r d.outliers.sum.F1F2 %>% group_by(Normalization.Type) %>% summarise(outlier_N = sum(outlier_N)) %>% summarise(sd(outlier_N)) %>% pull() %>% round(digits = 1)`) outliers. @Syrdal1986 and @miller1989c however, generated N =`r nrow(d.outliers %>% filter(Normalization.Type == "SyrdalGopal (Bark)", outlier_F1F2 == TRUE))`, and N=`r nrow(d.outliers %>% filter(Normalization.Type == "Miller (log)", outlier_F1F2 == TRUE))` outliers, respectively.

(ref:swe-vowels-outliers) Distributional outliers in the unnormalized and normalized data used for evaluating normalization accounts in Study I. Bars indicate proportion of outliers outside of the `r 100 * (outlier_probability_cutoff/2)`th to `r 100 * (1 - outlier_probability_cutoff/2)`th quantiles.

```{r swe-vowels-outliers, fig.cap="(ref:swe-vowels-outliers)"}
d.outliers.sum.F1F2 %>%
  mutate(category = factor(category, levels = levels.vowel.IPA.swe)) %>%
  ggplot(
    aes(
      x = category,
      y = outliers_prop,
      fill = Normalization.Type,
      color = Normalization.Type)) +
  geom_line(aes(y = outliers_prop, group = Normalization.Type), alpha = .4) +
  geom_bar(stat = "identity", position = position_dodge()) +
  scale_y_continuous("Proportion of outliers")
```

Inspection reveal that these outliers come from different sources.
(ref:swe-vowels-outliers-long) Distributional outliers in the unnormalized and normalized long vowel test data used for evaluating normalization accounts in Study I. Points show all outliers outside of the `r 100 * (outlier_probability_cutoff/2)`th to `r 100 * (1 - outlier_probability_cutoff/2)`th quantiles. Category means are plotted opaquely. Top: vowels transformed to different perceptual scales. Middle: vowels in all scale-transformations further normalized to C-CuRE. Bottom two: vowels in six different normalization spaces.

```{r}
p.outliers.long <-
  d.SwehVd.forStudy.long %>%
  filter(Quantity == "long") %>%
    ggplot(
      aes(
        x = F2,
        y = F1,
        color = category)) +
    stat_ellipse() +
    geom_point(
      data = d.SwehVd.forStudy.long %>%
        filter(Quantity == "long") %>%
        group_by(category, Normalization.Type, Quantity) %>%
        summarise(
          F1 = mean(F1),
          F2 = mean(F2)),
      mapping = aes(
        colour = category),
      alpha = 1) +
    geom_point(
      data =
        d.outliers %>%
        filter(outlier_F1F2 == TRUE, Quantity == "long"),
        mapping = aes(
        colour = category,
        shape = Talker),
      alpha = .5) +
    scale_shape_manual(values = 0:17) +
    scale_colour_manual(name = "category", values = colors.vowel.swe) +
    scale_x_reverse("F2 (in Hz)", position = "top", breaks = scales::breaks_pretty(6)) +
    scale_y_reverse("F1 (in Hz)", position = "right", breaks = scales::breaks_pretty(6)) +
    guides(alpha = "none", color = "none", shape = "none") +
    facet_wrap(~ factor(Normalization.Type, levels = labels.normalization), scales = "free")
```

\begin{landscape}

```{r swe-vowels-outliers-long, fig.width=base.width * 5 + 5, fig.height=base.height * 5, fig.align='center', fig.cap="(ref:swe-vowels-outliers-long)"}
p.outliers.long
```

\end{landscape}

```{r}
p.outliers.short <- p.outliers.long %+%
  (d.SwehVd.forStudy.long %>%
  filter(Quantity == "short")) +
  geom_point(
      data = d.SwehVd.forStudy.long %>%
        filter(Quantity == "short") %>%
        group_by(category, Normalization.Type, Quantity) %>%
        summarise(
          F1 = mean(F1),
          F2 = mean(F2)),
      mapping = aes(
        colour = category),
      alpha = 1) +
    geom_point(
      data =
        d.outliers %>%
        filter(outlier_F1F2 == TRUE, Quantity == "short"),
        mapping = aes(
        colour = category,
        shape = Talker),
      alpha = .5)

```

(ref:swe-vowels-outliers-short) Distributional outliers in the unnormalized and normalized short vowel test data used for evaluating normalization accounts in Study I. Points show all outliers outside of the `r 100 * (outlier_probability_cutoff/2)`th to `r 100 * (1 - outlier_probability_cutoff/2)`th quantiles. Category means are plotted opaquely. Top: vowels transformed to different perceptual scales. Middle: vowels in all scale-transformations further normalized to C-CuRE. Bottom two: vowels in six different normalization spaces.

\begin{landscape}

```{r swe-vowels-outliers-short, fig.width=base.width * 5 + 5, fig.height=base.height * 5, fig.align='center', fig.cap="(ref:swe-vowels-outliers-short)"}
p.outliers.short
```

\end{landscape}


While the exact number of identified outliers differed between accounts, some of them were outliers under all normalization accounts (see Figure \@ref(fig:outliers-across)). This suggests that there are talkers that use the vowel space in a way that makes some of their vowels outliers both before and after normalization.

(ref:outliers-across) Distributional outliers in the unnormalized and normalized data used for evaluating normalization accounts in Study I. Points show all outliers outside of the $`r 100 * (outlier_probability_cutoff/2)`$th to $`r 100 * (1 - outlier_probability_cutoff/2)`$th quantiles. Highlighted points are outliers under all normalization accounts.

\begin{landscape}

```{r outliers-across, fig.width=base.width * 5 + 5, fig.height=base.height * 5, fig.align='center', fig.cap="(ref:outliers-across)"}
# Plot the outliers that are the same across normalization accounts
d.outliers %<>%
  left_join(
    d.outliers %>%
      filter(outlier_F1F2 == TRUE) %>%
      distinct(Talker, Token, category, Normalization.Type) %>%
      group_by(Talker, Token, category) %>%
      tally() %>%
      filter(n == 16) %>%
      select(-n) %>%
      mutate(outlier_across = "TRUE"),
    by = c("Talker", "Token", "category"))

d.outliers %>%
  filter(outlier_F1F2 == TRUE) %>%
  mutate(Quantity = case_when(Quantity == "long" ~ 1, Quantity == "short" ~ .4)) %>%
  ggplot(
    aes(
      x = F2,
      y = F1,
      color = category)) +
  geom_point(
  data = NULL,
  aes(
    x=F2,
    y=F1,
    alpha = Quantity,
    shape = Talker)) +
  scale_shape_manual(values = 0:17) +
  scale_alpha(range = c(.4, 1)) +
  scale_colour_manual(name = "category", values = colors.vowel.swe) +
  scale_x_reverse("F2 (in Hz)", position = "top", breaks = scales::breaks_pretty(6)) +
  scale_y_reverse("F1 (in Hz)", position = "right", breaks = scales::breaks_pretty(6)) +
  guides(color = "none", alpha = "none", shape = guide_legend(nrow = 3)) +
  theme(axis.text.x = element_text(size=8.5, vjust=1),
        axis.text.y = element_text(size=8.5, hjust=1, vjust=.5),
        axis.title.x = element_text(size=8.5, vjust=0, hjust=0.5, face = "bold"),
        axis.title.y = element_text(size=8.5, hjust= 0.5, vjust=0.5, face = "bold"),
        legend.title = element_text(size=8.5, face = "bold", hjust= 0),
        legend.text = element_text(size=8.5)) +
  theme(legend.position="bottom", legend.box="horizontal") +
  facet_wrap(~ factor(Normalization.Type, levels = labels.normalization), scales = "free") +
  gghighlight::gghighlight(outlier_across == "TRUE", calculate_per_facet = TRUE)
```

\end{landscape}

Other outliers seem to be caused by some of the normalization accounts' failure to remove inter-talker variability.

```{r}
d.outliers %>%
  filter(outlier_F1F2 == TRUE, Normalization.Type %in% c("no normalization (Hz)", "SyrdalGopal (Bark)", "Miller (log)")) %>%
  mutate(Quantity = case_when(Quantity == "long" ~ 1, Quantity == "short" ~ .4)) %>%
  ggplot(
    aes(
      x = F2,
      y = F1,
      color = category)) +
  geom_point(
  data = NULL,
  aes(
    x=F2,
    y=F1,
    alpha = Quantity,
    shape = Talker)) +
  scale_shape_manual(values = 0:17) +
  scale_alpha(range = c(.4, 1)) +
  scale_colour_manual(name = "category", values = colors.vowel.swe) +
  scale_x_reverse("F2 (in Hz)", position = "top", breaks = scales::breaks_pretty(6)) +
  scale_y_reverse("F1 (in Hz)", position = "right", breaks = scales::breaks_pretty(6)) +
  guides(color = "none", alpha = "none", shape = guide_legend(nrow = 2)) +
  theme(legend.position="bottom", legend.box="horizontal") +
  facet_wrap(~ factor(Normalization.Type, levels = labels.normalization), scales = "free")
```


```{r}
# Calculate differences in by-talker means and by-talker variances per normalization procedure
d.SwehVd.forStudy.meanVariances <- d.SwehVd.forStudy.long %>%
  filter(fold_type == "test") %>%
  group_by(Normalization.Type, Talker, category) %>%
  summarise(
    across(
      .cols = c("F1", "F2"),
      .fns = list("variance" = ~ var(.x, na.rm = T))),
    across(
      .cols = c("F1", "F2"),
      .fns = list("mean" = ~ mean(.x, na.rm = T))),
    "category_cov" = cov(F1, F2)) %>%
  mutate(Talker = factor(Talker),
         category = factor(category))

# model <- glm(F1_mean ~ 1 + Normalization.Type * category + (1 + Normalization.Type * category | Talker), family =gaussian, data = d.SwehVd.forStudy.meanVariances)
# summary(model)
```


```{r}
#Remove d.outliers.sum
rm(d.outliers.sum)
```

Given that these two accounts change the vowel space more drastically than the other accounts in terms of category shape and orientation, the underlying assumption about categories being represented as Gaussian distributions for when calculating outliers, might not hold for these two accounts. Considering this uneven distribution of outliers across accounts, we decided to keep the identified outliers in the test data.


# Performance of ideal observer models on test data without distributional outliers
In Section \@ref(sec:distrProp), we visualized the outliers generated by the different normalization accounts. In order to have a balanced dataset, we decided to keep the identified outliers in the test data. Here, we plot the performance of the models where we have excluded all distributional outliers from the test data.

```{r}
```

# Normalizing constants
Table \@ref(tab:normalization-constants) show the constants obtained from training data, used for normalizing the test data.

```{r store-normalization-constants, echo=FALSE}
# Get 'constants' (variables required for different normalization accounts). This is done
# once for each cross-validation group (over all that group's training folds).
d.SwehVd.normalization_constants_based_on_training <-
  d.SwehVd.forStudy.long %>%
  filter(fold_type == "training") %>%
  group_by(crossvalidation_group) %>%
  summarise(
    across(
      .cols = starts_with("F", ignore.case = F),
      .fns = list(
        "mean" = ~ mean(.x, na.rm = T),
        "min" = ~ min(.x, na.rm = T),
        "max" = ~ max(.x, na.rm = T),
        "sd" = ~ sd(.x, na.rm = T),
        "se" = ~ se(.x),
        "mean_log" = ~ mean(log(.x), na.rm = T),
        "se_log" = ~ se(log(.x))),
      .names = "{.fn}_{.col}"),
    k = geometric.mean(mean(F0)),
    sum_mean_logF1_F3 = sum(mean(log(F1), na.rm = T), mean(log(F2), na.rm = T), mean(log(F3), na.rm = T)) / 3,
    sum_se_logF1_F3 = sum(se(log(F1)), se(log(F2)), se(log(F3))) / 3
  ) %>%
  mutate_if(is.numeric, round, digits = 3)
```


```{r normalization-constants, results='asis'}
# norm_constants %>%
#   kable(
#     format = "latex",
#     booktabs = TRUE,
#     caption = "Normalization constants obtained from training data") %>%
#   kable_styling(font_size = 7) %>%
#   column_spec(1:2, width = "2cm") %>%
#   column_spec(3:4, width = "6cm") %>%
#   column_spec(5:6, width = "2cm") %>%
#   landscape() %>%
#   collapse_rows()

#Remove constants dataframe after addressed in norm_accounts table
rm(d.SwehVd.normalization_constants_based_on_training)
```





